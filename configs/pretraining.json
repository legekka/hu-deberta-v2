{
    "name": "base-pretraining",
    "model": "models/hu-deberta-v2-base",
    "tokenizer": "models/hu-deberta-v2-base",
    "output_dir": "outputs/base-pretraining",
    "train_dataset": "uonlp/CulturaX",
    "train_dataset_kwargs": {
        "name": "hu",
        "split": "train[:99%]"
    },
    "eval_dataset": "uonlp/CulturaX",
    "eval_dataset_kwargs": {
        "name": "hu",
        "split": "train[99%:]"
    },
    "max_seq_length": 1024,
    "batch_size": 8,
    "gradient_accumulation_steps": 2,
    "num_epochs": 1,
    "num_workers": 2,
    "learning_rate": 1e-4,
    "warmup_steps": 100,
    "mlm_probability": 0.15,
    "optimizer": "adamw_torch",
    "scheduler": "cosine",
    "logging_steps": 100,
    "save_steps": 10000,
    "wandb": {
        "project": "hu-deberta-v2",
        "name": "base-pretraining",
        "tags": ["pretraining", "base"]
    }
}